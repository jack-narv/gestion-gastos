# ğŸ§ª Entorno de Pruebas Automatizadas
Backend Flask â€“ Registro de Gastos Personales

Este documento describe cÃ³mo configurar, ejecutar y comprender las pruebas automatizadas del backend de la aplicaciÃ³n Registro de Gastos Personales, desarrolladas con Pytest y generadas mediante asistencia de Inteligencia Artificial.

# ğŸ“Œ Objetivo de las pruebas

El objetivo de este entorno de pruebas es:

- Validar el correcto funcionamiento de la API REST desarrollada en Flask.

- Verificar los endpoints crÃ­ticos del sistema.

- Comprobar la persistencia de datos en el archivo JSON.

- Detectar errores funcionales de manera automatizada.

- Facilitar la replicabilidad del proceso de testing.

# ğŸ—ï¸ Alcance de las pruebas

Las pruebas cubren exclusivamente el backend de la aplicaciÃ³n.

Funcionalidades evaluadas:

- Endpoint GET /gastos

- Endpoint POST /gastos

- Persistencia de los datos en gastos.json

- CÃ³digos de estado HTTP correctos (200 y 201)

âš ï¸ No se incluyen pruebas de interfaz grÃ¡fica ni pruebas end-to-end.

# ğŸ§° TecnologÃ­as utilizadas

- Python 3.14.2

- Flask

- Pytest

- Entorno virtual (venv)

# âš™ï¸ Requisitos previos

Antes de ejecutar las pruebas, asegÃºrate de tener instalado:

- Python 3.10 o superior

- pip

- Git (opcional)

# ğŸš€ ConfiguraciÃ³n del entorno de pruebas

1ï¸âƒ£ Clonar el repositorio

git clone <URL_DEL_REPOSITORIO>

cd control-gastos/gastos-backend

2ï¸âƒ£ Crear entorno virtual

python -m venv venv

3ï¸âƒ£ Activar entorno virtual

Windows (PowerShell):

.\venv\Scripts\Activate

Linux / macOS:

source venv/bin/activate


La activaciÃ³n correcta se confirma cuando aparece (venv) en la terminal.

4ï¸âƒ£ Instalar dependencias del backend

pip install -r requirements.txt

5ï¸âƒ£ Instalar dependencias de testing

pip install -r requirements-test.txt

# ğŸ§ª EjecuciÃ³n de las pruebas

Desde la carpeta gastos-backend, con el entorno virtual activo:

pytest

Resultado esperado:
==================== test session starts ====================
collected 3 items

tests/test_gastos.py ...                              [100%]

===================== 3 passed in X.XXs =====================

# ğŸ§  DescripciÃ³n de los casos de prueba

âœ” test_get_gastos

- Verifica que el endpoint /gastos responde correctamente.

- Comprueba que la respuesta es una lista JSON.

- Valida el cÃ³digo HTTP 200.

âœ” test_post_gasto

- EnvÃ­a un nuevo gasto mediante una peticiÃ³n POST.

- Verifica que el backend devuelve cÃ³digo HTTP 201.

- Confirma que el endpoint acepta datos vÃ¡lidos.

âœ” test_persistencia_gasto

- Realiza una consulta GET tras registrar un gasto.

- Verifica que la lista no estÃ© vacÃ­a.

- Comprueba que los campos esperados existen en el objeto gasto.

# âŒ SimulaciÃ³n de un test fallido (documentado)

Durante el desarrollo del entorno de pruebas se simulÃ³ un fallo intencional:

- Se validÃ³ un campo inexistente (categoria) en la respuesta JSON.

- Pytest detectÃ³ correctamente el error (KeyError).

- El test fue corregido ajustÃ¡ndolo al modelo real de datos.

- Este proceso permitiÃ³ validar la eficacia del testing automatizado y la correcciÃ³n asistida por IA.

# âš ï¸ Consideraciones importantes

- Las pruebas utilizan el archivo gastos.json como persistencia real.

- Al ejecutar los tests, el archivo puede modificarse.

- Para entornos productivos se recomienda usar archivos mock o temporales.

# ğŸ¤– Uso de Inteligencia Artificial

Todo el cÃ³digo de pruebas fue generado mediante interacciÃ³n con un asistente de IA.
El rol del desarrollador fue:

- Definir el alcance de las pruebas.

- Formular prompts claros.

- Ejecutar y analizar los resultados.

- Solicitar correcciones cuando se detectaron fallos.

- No se escribiÃ³ cÃ³digo de pruebas manualmente.

# ğŸ“„ Licencia

Este entorno de pruebas fue desarrollado con fines acadÃ©micos.